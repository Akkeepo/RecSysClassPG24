{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51ae148b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib import request\n",
    "import zipfile\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48bde53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_URL = 'http://files.grouplens.org/datasets/movielens/ml-100k.zip'\n",
    "DATASET_ARCHIVE = 'ml-100k.zip'\n",
    "\n",
    "request.urlretrieve(DATASET_URL, DATASET_ARCHIVE)\n",
    "with zipfile.ZipFile(DATASET_ARCHIVE) as archive:\n",
    "    archive.extractall()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03fb279c",
   "metadata": {},
   "source": [
    "### 2. Prepare error metrics: RMSE\n",
    "Your Task:\n",
    "1. Prepare 2 functions that will calculate the goodness of fit: RMSE and HR@n\n",
    "2. RMSE:\n",
    "$RMSE(R,\\hat{R})=\\sqrt{1/n \\sum{(r - \\hat{r})^2}}$ <br/>\n",
    "$n\\  - \\text{# ratings in Y}$ <br/>\n",
    "$R\\  - \\text{ground true ratings}$ <br/>\n",
    "$\\hat{R}\\ - \\text{predictions of your model}$ <br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7c13fa69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(R,R_hat,index):\n",
    "    \"\"\"\n",
    "    Calculates RMSE between true ratings R and ratings estimations R_hat for index.\n",
    "    params:\n",
    "         R (np.array): rank 2 matrix of (ground) true ratings\n",
    "         R_hat (np.array): rank 2 matrix of ratings' predictions R.shape = R_hat.shape\n",
    "         index (np.array): index of R and R_hat for which RMSE needs to be calculated\n",
    "    returns:\n",
    "         RMSE value\n",
    "        \n",
    "    \"\"\"\n",
    "    #YOUR TASK: implement RMSE\n",
    "    X = np.multiply((R-R_hat), index)\n",
    "    Y = np.sum(np.multiply(X,X))\n",
    "    Z= np.sum(index)\n",
    "    return np.sqrt(Y / Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb43885",
   "metadata": {},
   "source": [
    "### 3. Prepare error metrics HR@n (please solve after you implement MF with ALS)\n",
    "\n",
    "Your task: write a function that calculates HR@n\n",
    "\n",
    "HR(u)@n for a single user u is calculated when the number of recommended items for that user is n. If out of n recommended items m (m<=n) were consumed by user then:\n",
    "\n",
    "#### $HR@n(u) = \\frac{m}{n}$ <br/>\n",
    "\n",
    "Overall HR@n is just an average over all users:\n",
    "#### $HR@n = \\frac{1}{n_u} \\sum{\\frac{m}{n}}$ <br/>\n",
    " \n",
    "be careful with caveats with HR!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "36ee5b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def HR_at_n(R,R_hat,R_exclude,n=10):\n",
    "    \"\"\"\n",
    "    Calculates RMSE between true ratings R and ratings estimations R_hat for index.\n",
    "    params:\n",
    "         R (np.array): rank 2 matrix of (ground) true ratings\n",
    "         R_hat (np.array): rank 2 matrix of ratings' predictions R.shape = R_hat.shape\n",
    "         R_exclude (np.array): rank 2 matrix of ratings to be excluded i.e. if R_exclude[u,i]>0 then item i for user u has to be excluded from HR calculation (e.g. it was used for training)\n",
    "         n (int): length of recommendation\n",
    "    returns:\n",
    "         RMSE value\n",
    "        \n",
    "    \"\"\"\n",
    "    #YOUR TASK: implement HR@n function\n",
    "    R_hat = copy.copy(R_hat)\n",
    "    exclude_items_per_user =  np.sum(R_exclude>0,axis=1)\n",
    "    R_hat[R_exclude>0] = -np.inf\n",
    "    pred_items = np.argsort(-R_hat,axis=1)\n",
    "    true_items = np.argsort(-R,axis=1)\n",
    "    exclude_items_cnt = np.sum(R_exclude>0,axis=1)\n",
    "    test_items_cnt = np.sum(R>0,axis=1)\n",
    "    hr_total = 0\n",
    "    for user_id in range(pred_items.shape[0]):\n",
    "            min_end = min(n,pred_items.shape[1]-exclude_items_cnt[user_id])\n",
    "            pred_items_for_user = pred_items[user_id,:min_end]\n",
    "            propper_itemscnt_for_user = np.sum(np.in1d(pred_items_for_user,true_items[user_id,:test_items_cnt[user_id]]))\n",
    "            if test_items_cnt[user_id]>0:\n",
    "                hr_for_user = propper_itemscnt_for_user/min(n,test_items_cnt[user_id])\n",
    "                hr_total += hr_for_user\n",
    "    hr_total /= np.shape(R)[0]\n",
    "    return hr_total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907382bf",
   "metadata": {},
   "source": [
    "### 4.Plotting function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "b7c6c901",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(model):\n",
    "    \"\"\"visualize the training/testing loss\"\"\"\n",
    "    linewidth = 1\n",
    "    \n",
    "    fig = plt.figure(figsize=(15,5))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.plot(model.test_rmse_record, label = 'Test', linewidth = linewidth)\n",
    "    plt.plot(model.train_rmse_record, label = 'Train', linewidth = linewidth)\n",
    "    plt.xlabel('iterations')\n",
    "    plt.ylabel('RMSE')\n",
    "    plt.legend(loc = 'best')\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.plot(model.test_hr, label = 'Test', linewidth = linewidth)\n",
    "    plt.plot(model.train_hr, label = 'Train', linewidth = linewidth)\n",
    "    plt.xlabel('iterations')\n",
    "    plt.ylabel('HR@{}'.format(model.hr_n))\n",
    "    plt.legend(loc = 'best')\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.plot(model.loss, label = 'train loss', linewidth = linewidth)\n",
    "    plt.xlabel('steps')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend(loc = 'best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c102cf",
   "metadata": {},
   "source": [
    "### 4. Main part: iplementation of ALS, but batched version\n",
    "\n",
    "Your task: implement a ALS MF batched recommender. This is iterative algorithm and MF_ALS class implements it.\n",
    "    \n",
    "#### 1. We will factorise rating matrix R so that $R\\approx \\hat{R}= XY^T$ , \n",
    "#### 2. Every step of this iteration calculates X and Y which are in fact embeedings for users (X) and items (Y) and there will be n_iters iterations (epochs), however now each update will be based on the batch of data rather than entire matrix R\n",
    "#### 3. $X \\in R^{n_u\\ x\\ \\text{n_factors}}$ $Y \\in R^{n_i\\ x\\ \\text{n_factors}}$ X, Y can be initialised uniformlly [0,1]\n",
    "#### 4. We want it to be a regularised version of ALS (reg>0), but you can start without it for simplicity\n",
    "#### 5. After every iteration we want to log the RMSE,  HR@n and train loss using functions that you have developed above\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "23fd68da",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MF_ALS_Batched:\n",
    "    \"\"\"\n",
    "    Train a matrix factorization model using Alternating Least Squares\n",
    "    to predict empty entries in a matrix\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    n_iters : int\n",
    "        number of iterations to train the algorithm\n",
    "        \n",
    "    n_factors : int\n",
    "        number of latent factors to use in matrix \n",
    "        factorization model, some machine-learning libraries\n",
    "        denote this as rank\n",
    "        \n",
    "    reg : float\n",
    "        regularization term for item/user latent factors,\n",
    "        since lambda is a keyword in python we use reg instead\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_iters, n_factors, reg):\n",
    "        self.reg = reg\n",
    "        self.n_iters = n_iters\n",
    "        self.n_factors = n_factors  \n",
    "        \n",
    "\n",
    "    def fit(self,train,test,lr=0.01,BS=1000,n=10):\n",
    "        #YOUR TASK 1: get arrays of user_ids and item_ids and corresponding ratings\n",
    "        u_id=(train>0).nonzero()[0]\n",
    "        i_id=(train>0).nonzero()[1]\n",
    "        r = train[np.nonzero(train)]\n",
    "        self.n_user, self.n_item =np.max(u_id)+1, np.max(i_id)+1\n",
    "        #YOUR TASK 2: initialise X, Y uniformly [0,1]\n",
    "        self.user_factors = np.random.random((self.n_user, self.n_factors))\n",
    "        self.item_factors = np.random.random((self.n_item, self.n_factors))\n",
    "        n_cnt = u_id.shape[0] # dataset size     \n",
    "        self.test_rmse_record  = []\n",
    "        self.train_rmse_record = []\n",
    "        self.loss = []\n",
    "        self.test_hr = []\n",
    "        self.train_hr = []\n",
    "        self.hr_n = n \n",
    "        for e in range(self.n_iters):\n",
    "            for b in range(u_id.shape[0]//BS):\n",
    "                #YOUR TASK3: get boundaries of batch and all ratings (R_batch) that are in this batch \n",
    "                bmin = b*BS\n",
    "                bmax = min((b+1)*BS,n)\n",
    "                R_batch = np.zeros(shape=(self.n_user,self.n_item))\n",
    "                R_batch[u_id[bmin:bmax],i_id[bmin:bmax]] = r[bmin:bmax]\n",
    "                #YOUR TASK4: calculate train loss (for logging), remember about regularisation\n",
    "                loss_part = np.power(R_batch - self.predict(),2)\n",
    "                L = (1.0/n_cnt) * np.sum(np.multiply(R_batch!=0,loss_part)) + self.reg*np.sum(np.power(self.user_factors,2)) + self.reg*np.sum(np.power(self.item_factors,2)) \n",
    "                \n",
    "                self.loss.append(L)\n",
    "                #YOUR TASK5: calculate derivative of loss with respect to X and Y, update X, Y\n",
    "                dX = (1/n_cnt)*2*np.multiply(R_batch!=0,R_batch-self.predict()).dot(self.item_factors) + 2*self.reg*self.user_factors\n",
    "                self.user_factors = self.user_factors - lr*dX\n",
    "                dY = (1/n_cnt)*(2*self.user_factors.T.dot(np.multiply(R_batch!=0,R_batch-self.predict()))).T + 2*self.reg*self.item_factors\n",
    "                self.item_factors = self.item_factors - lr*dY\n",
    "            predictions = self.predict()\n",
    "            test_rmse = self.compute_rmse(test, predictions)\n",
    "            train_rmse = self.compute_rmse(train, predictions)\n",
    "            test_hr = self.compute_hr_at_n(test,predictions,train,n)\n",
    "            train_hr = self.compute_hr_at_n(train,predictions,np.zeros_like(train),n)\n",
    "            self.test_rmse_record.append(test_rmse)\n",
    "            self.train_rmse_record.append(train_rmse)\n",
    "            self.test_hr.append(test_hr)\n",
    "            self.train_hr.append(train_hr)\n",
    "        \n",
    "    \n",
    "    def predict(self):\n",
    "        \"\"\"predict ratings for every user and item\"\"\"\n",
    "        pred = self.user_factors.dot(self.item_factors.T)\n",
    "        return pred\n",
    "    \n",
    "    @staticmethod\n",
    "    def compute_rmse(R, R_hat):\n",
    "        \"\"\"ignore zero terms prior to comparing the mse\"\"\"\n",
    "        rmse_val = rmse(R,R_hat,R>=1)\n",
    "        return rmse_val\n",
    "    \n",
    "    @staticmethod\n",
    "    def compute_hr_at_n(R,R_hat,R_exclue,n):\n",
    "        return HR_at_n(R,R_hat,R_exclue,n)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e400efb4",
   "metadata": {},
   "source": [
    "#### 5. Time for test!\n",
    "\n",
    "1. What are HyperParams of this algorithm?\n",
    "2. Can you find best ones?\n",
    "3. What are conclussions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "e189e56b",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-118-01b636d21006>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m                              delim_whitespace=True)\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m#YOUR TASK: get train and test R, fit the model, plot learning curve\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     train = np.array(pd.crosstab(index=pd.Categorical(train['user_id'],categories = [i for i in range(1,943+1)]), \n\u001b[0m\u001b[1;32m      8\u001b[0m                                                     \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCategorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'item_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcategories\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1682\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                                                     values=train['rating'], aggfunc=np.sum, dropna= False).fillna(0).values)\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/reshape/pivot.py\u001b[0m in \u001b[0;36mcrosstab\u001b[0;34m(index, columns, values, rownames, colnames, aggfunc, margins, margins_name, dropna, normalize)\u001b[0m\n\u001b[1;32m    614\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"aggfunc\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0maggfunc\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 616\u001b[0;31m     table = df.pivot_table(\n\u001b[0m\u001b[1;32m    617\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0;34m\"__dummy__\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m         \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrownames\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mpivot_table\u001b[0;34m(self, values, index, columns, aggfunc, fill_value, margins, dropna, margins_name, observed)\u001b[0m\n\u001b[1;32m   6824\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpivot\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpivot_table\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6825\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6826\u001b[0;31m         return pivot_table(\n\u001b[0m\u001b[1;32m   6827\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6828\u001b[0m             \u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/reshape/pivot.py\u001b[0m in \u001b[0;36mpivot_table\u001b[0;34m(data, values, index, columns, aggfunc, fill_value, margins, dropna, margins_name, observed)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0mgrouped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobserved\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobserved\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m     \u001b[0magged\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrouped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maggfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdropna\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magged\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCDataFrame\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magged\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0magged\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magged\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"all\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/groupby/generic.py\u001b[0m in \u001b[0;36maggregate\u001b[0;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    949\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_mangle_lambdas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 951\u001b[0;31m         \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_aggregate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    952\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhow\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/base.py\u001b[0m in \u001b[0;36m_aggregate\u001b[0;34m(self, arg, *args, **kwargs)\u001b[0m\n\u001b[1;32m    484\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_cython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0margs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 486\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    487\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;31m# caller can react\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36msum\u001b[0;34m(self, numeric_only, min_count)\u001b[0m\n\u001b[1;32m   1539\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_groupby_agg_method_template\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"sum\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mno\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumeric_only\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_count\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1541\u001b[0;31m         return self._agg_general(\n\u001b[0m\u001b[1;32m   1542\u001b[0m             \u001b[0mnumeric_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnumeric_only\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"add\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnpfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         )\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36m_agg_general\u001b[0;34m(self, numeric_only, min_count, alias, npfunc)\u001b[0m\n\u001b[1;32m    998\u001b[0m         \u001b[0;31m# try a cython aggregation if we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1000\u001b[0;31m             result = self._cython_agg_general(\n\u001b[0m\u001b[1;32m   1001\u001b[0m                 \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnpfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumeric_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnumeric_only\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1002\u001b[0m             )\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/groupby/generic.py\u001b[0m in \u001b[0;36m_cython_agg_general\u001b[0;34m(self, how, alt, numeric_only, min_count)\u001b[0m\n\u001b[1;32m   1022\u001b[0m             \u001b[0mhow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumeric_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnumeric_only\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin_count\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m         )\n\u001b[0;32m-> 1024\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrap_agged_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magg_blocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0magg_items\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m     def _cython_agg_blocks(\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/groupby/generic.py\u001b[0m in \u001b[0;36m_wrap_agged_blocks\u001b[0;34m(self, blocks, items)\u001b[0m\n\u001b[1;32m   1755\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1756\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1757\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1758\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1759\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_iterate_column_groupbys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36m_reindex_output\u001b[0;34m(self, output, fill_value)\u001b[0m\n\u001b[1;32m   2725\u001b[0m                 \u001b[0;34m\"fill_value\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2726\u001b[0m             }\n\u001b[0;32m-> 2727\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2729\u001b[0m         \u001b[0;31m# GH 13204\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m         \u001b[0mkind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParameter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPOSITIONAL_OR_KEYWORD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mreindex\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   4034\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"axis\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4035\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"labels\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4036\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4037\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4038\u001b[0m     def drop(\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mreindex\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   4459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4460\u001b[0m         \u001b[0;31m# perform the reindex on the axes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4461\u001b[0;31m         return self._reindex_axes(\n\u001b[0m\u001b[1;32m   4462\u001b[0m             \u001b[0maxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4463\u001b[0m         ).__finalize__(self, method=\"reindex\")\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_reindex_axes\u001b[0;34m(self, axes, level, limit, tolerance, method, fill_value, copy)\u001b[0m\n\u001b[1;32m   3880\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"index\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3881\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3882\u001b[0;31m             frame = frame._reindex_index(\n\u001b[0m\u001b[1;32m   3883\u001b[0m                 \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3884\u001b[0m             )\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_reindex_index\u001b[0;34m(self, new_index, method, copy, level, fill_value, limit, tolerance)\u001b[0m\n\u001b[1;32m   3896\u001b[0m         \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3897\u001b[0m     ):\n\u001b[0;32m-> 3898\u001b[0;31m         new_index, indexer = self.index.reindex(\n\u001b[0m\u001b[1;32m   3899\u001b[0m             \u001b[0mnew_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3900\u001b[0m         )\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/indexes/multi.py\u001b[0m in \u001b[0;36mreindex\u001b[0;34m(self, target, method, level, limit, tolerance)\u001b[0m\n\u001b[1;32m   2313\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2314\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2315\u001b[0;31m                     indexer = self.get_indexer(\n\u001b[0m\u001b[1;32m   2316\u001b[0m                         \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2317\u001b[0m                     )\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/indexes/multi.py\u001b[0m in \u001b[0;36mget_indexer\u001b[0;34m(self, target, method, limit, tolerance)\u001b[0m\n\u001b[1;32m   2468\u001b[0m             )\n\u001b[1;32m   2469\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2470\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2472\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mensure_platform_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.BaseMultiIndexCodesEngine.get_indexer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.BaseMultiIndexCodesEngine.get_indexer_no_fill\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.BaseMultiIndexCodesEngine._extract_level_codes\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/indexes/category.py\u001b[0m in \u001b[0;36mget_indexer\u001b[0;34m(self, target, method, limit, tolerance)\u001b[0m\n\u001b[1;32m    571\u001b[0m                 \u001b[0mcodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategories\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m         \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    574\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mensure_platform_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_indexer_non_unique\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mresize\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for fold in range(1,6):\n",
    "    train = pd.read_csv('ml-100k/u{}.base'.format(fold), header=None, names=['user_id', 'item_id', 'rating', 'timestamp'], \n",
    "                             delim_whitespace=True)\n",
    "    test = pd.read_csv('ml-100k/u{}.test'.format(fold), header=None, names=['user_id', 'item_id', 'rating', 'timestamp'], \n",
    "                             delim_whitespace=True)\n",
    "    #YOUR TASK: get train and test R, fit the model, plot learning curve\n",
    "    train = np.array(pd.crosstab(index=pd.Categorical(train['user_id'],categories = [i for i in range(1,943+1)]), \n",
    "                                                    columns=pd.Categorical(train['item_id'],categories = [i for i in range(1,1682+1)]),\n",
    "                                                    values=train['rating'], aggfunc=np.sum, dropna= False).fillna(0).values)\n",
    "    test = np.array(pd.crosstab(index=pd.Categorical(test['user_id'],categories = [i for i in range(1,943+1)]), \n",
    "                                                    columns=pd.Categorical(test['item_id'],categories = [i for i in range(1,1682+1)]),\n",
    "                                                    values=test['rating'], aggfunc=np.sum, dropna= False).fillna(0).values)\n",
    "\n",
    "    als = MF_ALS_Batched(n_iters = 10, n_factors = 64, reg = 0.001)\n",
    "    als.fit(train,test,lr=1,BS=1000)\n",
    "    plot_learning_curve(als)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "77d3fa10",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.array(pd.crosstab(index=pd.Categorical(train['user_id'],categories = [i for i in range(1,943+1)]), \n",
    "                                                    columns=pd.Categorical(train['item_id'],categories = [i for i in range(1,1682+1)]),\n",
    "                                                    values=train['rating'], aggfunc=np.sum, dropna= False).fillna(0).values)\n",
    "test = np.array(pd.crosstab(index=pd.Categorical(test['user_id'],categories = [i for i in range(1,943+1)]), \n",
    "                                                    columns=pd.Categorical(test['item_id'],categories = [i for i in range(1,1682+1)]),\n",
    "                                                    values=test['rating'], aggfunc=np.sum, dropna= False).fillna(0).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06015b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "als = MF_ALS_Batched(n_iters = 10, n_factors = 64, reg = 0.001)\n",
    "als.fit(train,test,lr=1,BS=1000)\n",
    "plot_learning_curve(als)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7192a7c1",
   "metadata": {},
   "source": [
    "#### 6. How to modify the above code so that:\n",
    "\n",
    "We would have ratings {0,1} only instead of {1,2,3,4,5}. What will it change?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae62f5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold in range(1,6):\n",
    "    train = pd.read_csv('ml-100k/u{}.base'.format(fold), header=None, names=['user_id', 'item_id', 'rating', 'timestamp'], \n",
    "                             delim_whitespace=True)\n",
    "    test = pd.read_csv('ml-100k/u{}.test'.format(fold), header=None, names=['user_id', 'item_id', 'rating', 'timestamp'], \n",
    "                             delim_whitespace=True)\n",
    "    #YOUR TASK: get train and test R, fit the model, plot learning curve\n",
    "    train = np.array(pd.crosstab(index=pd.Categorical(train['user_id'],categories = [i for i in range(1,943+1)]), \n",
    "                                                    columns=pd.Categorical(train['item_id'],categories = [i for i in range(1,1682+1)]),\n",
    "                                                    values=train['rating'], aggfunc=np.sum, dropna= False).fillna(0).values)\n",
    "    test = np.array(pd.crosstab(index=pd.Categorical(test['user_id'],categories = [i for i in range(1,943+1)]), \n",
    "                                                    columns=pd.Categorical(test['item_id'],categories = [i for i in range(1,1682+1)]),\n",
    "                                                    values=test['rating'], aggfunc=np.sum, dropna= False).fillna(0).values)\n",
    "    train_ratings_matrix[train_ratings_matrix>0] = 1\n",
    "    test_ratings_matrix[test_ratings_matrix>0] = 1\n",
    "    als = MF_ALS_Batched(n_iters = 5, n_factors = 64, reg = 0.001)\n",
    "    als.fit(train,test,lr=5000,BS=10000000)\n",
    "    plot_learning_curve(als)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
