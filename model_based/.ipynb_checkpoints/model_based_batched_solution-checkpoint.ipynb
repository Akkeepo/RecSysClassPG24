{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55b2cd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib import request\n",
    "import zipfile\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df9b992e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_URL = 'http://files.grouplens.org/datasets/movielens/ml-100k.zip'\n",
    "DATASET_ARCHIVE = 'ml-100k.zip'\n",
    "\n",
    "request.urlretrieve(DATASET_URL, DATASET_ARCHIVE)\n",
    "with zipfile.ZipFile(DATASET_ARCHIVE) as archive:\n",
    "    archive.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3fbe872c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(ratings_matrix,recommendation_matrix, test_ind):\n",
    "    X = np.multiply((ratings_matrix-recommendation_matrix), test_ind)\n",
    "    Y = np.sum(np.multiply(X,X))\n",
    "    Z= np.sum(test_ind)\n",
    "    return np.sqrt(Y / Z)\n",
    "\n",
    "def HR_at_n(y_true,y_pred,y_exclude,n=10):\n",
    "    y_pred = copy.copy(y_pred)\n",
    "    exclude_items_per_user =  np.sum(y_exclude>0,axis=1)\n",
    "    y_pred[y_exclude>0] = -np.inf\n",
    "    pred_items = np.argsort(-y_pred,axis=1)\n",
    "    true_items = np.argsort(-y_true,axis=1)\n",
    "    exclude_items_cnt = np.sum(y_exclude>0,axis=1)\n",
    "    test_items_cnt = np.sum(y_true>0,axis=1)\n",
    "    hr_total = 0\n",
    "    for user_id in range(pred_items.shape[0]):\n",
    "            min_end = min(n,pred_items.shape[1]-exclude_items_cnt[user_id])\n",
    "            pred_items_for_user = pred_items[user_id,:min_end]\n",
    "            propper_itemscnt_for_user = np.sum(np.in1d(pred_items_for_user,true_items[user_id,:test_items_cnt[user_id]]))\n",
    "            if test_items_cnt[user_id]>0:\n",
    "                hr_for_user = propper_itemscnt_for_user/min(n,test_items_cnt[user_id])\n",
    "                hr_total += hr_for_user\n",
    "    hr_total /= np.shape(y_true)[0]\n",
    "    return hr_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "40c589d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(model):\n",
    "    \"\"\"visualize the training/testing loss\"\"\"\n",
    "    linewidth = 1\n",
    "    \n",
    "    fig = plt.figure(figsize=(15,15))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.plot(model.test_rmse_record, label = 'Test', linewidth = linewidth)\n",
    "    plt.plot(model.train_rmse_record, label = 'Train', linewidth = linewidth)\n",
    "    plt.xlabel('iterations')\n",
    "    plt.ylabel('RMSE')\n",
    "    plt.legend(loc = 'best')\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.plot(model.test_hr, label = 'Test', linewidth = linewidth)\n",
    "    plt.plot(model.train_hr, label = 'Train', linewidth = linewidth)\n",
    "    plt.xlabel('iterations')\n",
    "    plt.ylabel('HR@{}'.format(model.hr_n))\n",
    "    plt.legend(loc = 'best')\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.plot(model.loss, label = 'train loss', linewidth = linewidth)\n",
    "    plt.xlabel('steps')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend(loc = 'best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "93e231a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExplicitMF:\n",
    "    \"\"\"\n",
    "    Train a matrix factorization model using Alternating Least Squares\n",
    "    to predict empty entries in a matrix\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    n_iters : int\n",
    "        number of iterations to train the algorithm\n",
    "        \n",
    "    n_factors : int\n",
    "        number of latent factors to use in matrix \n",
    "        factorization model, some machine-learning libraries\n",
    "        denote this as rank\n",
    "        \n",
    "    reg : float\n",
    "        regularization term for item/user latent factors,\n",
    "        since lambda is a keyword in python we use reg instead\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_iters, n_factors, reg):\n",
    "        self.reg = reg\n",
    "        self.n_iters = n_iters\n",
    "        self.n_factors = n_factors  \n",
    "        \n",
    "    def fit(self, train, test,n=10):\n",
    "        \"\"\"\n",
    "        pass in training and testing at the same time to record\n",
    "        model convergence, assuming both dataset is in the form\n",
    "        of User x Item matrix with cells as ratings\n",
    "        \"\"\"\n",
    "        self.n_user, self.n_item = train.shape\n",
    "        self.user_factors = np.random.random((self.n_user, self.n_factors))\n",
    "        self.item_factors = np.random.random((self.n_item, self.n_factors))\n",
    "        # record the training and testing mse for every iteration\n",
    "        # to show convergence later (usually, not worth it for production)\n",
    "        self.test_rmse_record  = []\n",
    "        self.train_rmse_record = []  \n",
    "        self.test_hr = []\n",
    "        self.train_hr = []\n",
    "        self.hr_n = n \n",
    "        for _ in range(self.n_iters):\n",
    "            self.user_factors = self._als_step(train, self.user_factors, self.item_factors)\n",
    "            self.item_factors = self._als_step(train.T, self.item_factors, self.user_factors)             \n",
    "            predictions = self.predict()\n",
    "            test_rmse = self.compute_rmse(test, predictions)\n",
    "            train_rmse = self.compute_rmse(train, predictions)\n",
    "            test_hr = self.compute_hr_at_n(test,predictions,train,n)\n",
    "            train_hr = self.compute_hr_at_n(train,predictions,np.zeros_like(train),n)\n",
    "            self.test_rmse_record.append(test_rmse)\n",
    "            self.train_rmse_record.append(train_rmse)\n",
    "            self.test_hr.append(test_hr)\n",
    "            self.train_hr.append(train_hr)\n",
    "        return self    \n",
    "    \n",
    "    \n",
    "    def fit_batch(self,train,test,lr=0.01,BS=1000,n=10):\n",
    "        u_id=(train>0).nonzero()[0]\n",
    "        i_id=(train>0).nonzero()[1]\n",
    "        r = train[np.nonzero(train)]\n",
    "        self.n_user, self.n_item =np.max(u_id)+1, np.max(i_id)+1\n",
    "        self.user_factors = np.random.random((self.n_user, self.n_factors))\n",
    "        self.item_factors = np.random.random((self.n_item, self.n_factors))\n",
    "        n_cnt = u_id.shape[0]      \n",
    "        self.test_rmse_record  = []\n",
    "        self.train_rmse_record = []\n",
    "        self.loss = []\n",
    "        self.test_hr = []\n",
    "        self.train_hr = []\n",
    "        self.hr_n = n \n",
    "        for e in range(self.n_iters):\n",
    "            for b in range(u_id.shape[0]//BS):\n",
    "                bmin = b*BS\n",
    "                bmax = min((b+1)*BS,n)\n",
    "                R_batch = np.zeros(shape=(self.n_user,self.n_item))\n",
    "                R_batch[u_id[bmin:bmax],i_id[bmin:bmax]] = r[bmin:bmax]\n",
    "                loss_part = np.power(R_batch - self.predict(),2)\n",
    "                L = (1.0/BS) * np.sum(np.multiply(R_batch!=0,loss_part)) + self.reg*np.sum(np.power(self.user_factors,2)) + self.reg*np.sum(np.power(self.item_factors,2)) \n",
    "                #print(L)\n",
    "                self.loss.append(L)\n",
    "                \n",
    "                dX = (1/BS)*2*np.multiply(R_batch!=0,R_batch-self.predict()).dot(self.item_factors) + 2*self.reg*self.user_factors\n",
    "                self.user_factors = self.user_factors - lr*dX\n",
    "                dY = (1/BS)*(2*self.user_factors.T.dot(np.multiply(R_batch!=0,R_batch-self.predict()))).T + 2*self.reg*self.item_factors\n",
    "                self.item_factors = self.item_factors - lr*dY\n",
    "            predictions = self.predict()\n",
    "            test_rmse = self.compute_rmse(test, predictions)\n",
    "            train_rmse = self.compute_rmse(train, predictions)\n",
    "            test_hr = self.compute_hr_at_n(test,predictions,train,n)\n",
    "            train_hr = self.compute_hr_at_n(train,predictions,np.zeros_like(train),n)\n",
    "            self.test_rmse_record.append(test_rmse)\n",
    "            self.train_rmse_record.append(train_rmse)\n",
    "            self.test_hr.append(test_hr)\n",
    "            self.train_hr.append(train_hr)\n",
    "        \n",
    "        \n",
    "    \n",
    "    def _als_step(self, ratings, solve_vecs, fixed_vecs):\n",
    "        \"\"\"\n",
    "        when updating the user matrix,\n",
    "        the item matrix is the fixed vector and vice versa\n",
    "        \"\"\"\n",
    "        A = fixed_vecs.T.dot(fixed_vecs) + np.eye(self.n_factors) * self.reg\n",
    "        b = ratings.dot(fixed_vecs)\n",
    "        A_inv = np.linalg.inv(A)\n",
    "        solve_vecs = b.dot(A_inv)\n",
    "        return solve_vecs\n",
    "    \n",
    "    def predict(self):\n",
    "        \"\"\"predict ratings for every user and item\"\"\"\n",
    "        pred = self.user_factors.dot(self.item_factors.T)\n",
    "        return pred\n",
    "    \n",
    "    @staticmethod\n",
    "    def compute_rmse(y_true, y_pred):\n",
    "        \"\"\"ignore zero terms prior to comparing the mse\"\"\"\n",
    "        mask = np.nonzero(y_true)\n",
    "        rmse_val = rmse(y_pred,y_true,y_true>=1)\n",
    "        return rmse_val\n",
    "    \n",
    "    @staticmethod\n",
    "    def compute_hr_at_n(y_true,y_pred,y_exclue,n):\n",
    "        return HR_at_n(y_true,y_pred,y_exclue,n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f027d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "als = ExplicitMF(n_iters = 50, n_factors = 64, reg = 0.001)\n",
    "als.fit_batch(train,test,lr=0.5,BS=100)\n",
    "plot_learning_curve(als)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d6367c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
